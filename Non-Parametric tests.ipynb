{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebe392a4-992c-4fcf-9503-f84dec3a4c6d",
   "metadata": {},
   "source": [
    "# Nonparametric Statistical Significance Tests in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b01da7-88bd-442b-8b79-86aac6cee6eb",
   "metadata": {},
   "source": [
    "Nonparametric statistics are those methods that do not assume a specific distribution to the data.\n",
    "\n",
    "Often, they refer to statistical methods that do not assume a Gaussian distribution. They were developed for use with ordinal or interval data, but in practice can also be used with a ranking of real-valued observations in a data sample rather than on the observation values themselves.\n",
    "\n",
    "- To test whether the two data samples have the same or different distributions.\n",
    "\n",
    "- The null hypothesis of these tests is often the assumption that both samples were drawn from a population with the same distribution, and therefore the same population parameters, such as mean or median.\n",
    "\n",
    "- If after calculating the significance test on two or more samples the null hypothesis is rejected, it indicates that there is evidence to suggest that samples were drawn from different populations, and in turn the difference between sample estimates of population parameters, such as means or medians may be significant.\n",
    "\n",
    "- Tests also return a  p-value that can be used to interpret the result of the test. The  p-value can be thought of as the probability of observing the two data samples given the base assumption (null hypothesis) that the two samples were drawn from a population with the same distribution.\n",
    "\n",
    "- The p-value can be interpreted in the context of a chosen significance level called  α. A common value for alpha is 5% or 0.05. If the p-value is below the significance level, then the test says there is enough evidence to reject the null hypothesis and that the samples were likely drawn from populations with differing distributions.\n",
    "\n",
    "p<=α : reject H0, different distribution.\n",
    "\n",
    "p>α : fail to reject H0, same distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cc87499-6b79-4482-8783-0485443c0cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1: mean=50.303 stdv=4.426\n",
      "data2: mean=51.764 stdv=4.660\n"
     ]
    }
   ],
   "source": [
    "# generate gaussian data samples\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate two sets of univariate observations\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 51\n",
    "# summarize\n",
    "print('data1: mean=%.3f stdv=%.3f' % (mean(data1), std(data1)))\n",
    "print('data2: mean=%.3f stdv=%.3f' % (mean(data2), std(data2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa26a9cd-edc6-41e7-b9b1-fc8243c9782f",
   "metadata": {},
   "source": [
    "# The Mann-Whitney U test (for two independent samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d72eeff-9729-4d93-b77c-df78ad6dbb18",
   "metadata": {},
   "source": [
    "- The Mann-Whitney U test is a nonparametric statistical significance test for determining whether two independent samples were drawn from a population with the same distribution.\n",
    "  \n",
    "More specifically, the test determines whether it is equally likely that any randomly selected observation from one sample will be greater or less than a sample in the other distribution. If violated, it suggests differing distributions.\n",
    "\n",
    "- Fail to Reject H0: Sample distributions are equal.\n",
    "- Reject H0: Sample distributions are not equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6181ad4-5354-4436-b591-6a9b60481cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d15d1b9-e9db-47cd-9b5a-79351039ca7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=4025.000, p=0.017\n",
      "Different distribution (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# compare samples\n",
    "stat, p = mannwhitneyu(data1, data2)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distribution (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1152410-166b-42ed-a58a-b282ef0cb6a6",
   "metadata": {},
   "source": [
    "Mann-Whitney U test is used to assess the existence (or absence) of significant differences between two samples of numerical data.\n",
    "\n",
    "Python scipy library incorporates an implementation of this and other non-parametric test. The code below illustrates the application of the Mann-Whitney U test to compare the quality ratings between two groups of red wine samples associated with two Spanish regions: region A and region B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7cf9a2f-2d07-47b2-96a9-90da040ee033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region A ratings: [86 83 92 94 90 87 92 84 86 89 82 86 90 90 87 84 83 87 87 82 85 84 81 87\n",
      " 91 93 85 81 91 84]\n",
      "Region B ratings: [85 96 94 90 97 96 93 85 95 95 99 94 96 96 99 98 98 99 98 87 96 91 88 93\n",
      " 87 89 87 91 89 93]\n",
      "Mann-Whitney U statistic: 127.5\n",
      "P-value: 1.819820648463293e-06\n",
      "There is a significant difference in wine quality ratings between the two regions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# The two data samples, of size 30 each, are generated synthetically\n",
    "np.random.seed(42)\n",
    "region_a = np.random.randint(80, 95, size=30)\n",
    "region_b = np.random.randint(85, 100, size=30)\n",
    "\n",
    "# Apply Mann-Whitney U test\n",
    "stat, p_value = mannwhitneyu(region_a, region_b, alternative='two-sided')\n",
    "\n",
    "# Output the data\n",
    "print(f\"Region A ratings: {region_a}\")\n",
    "print(f\"Region B ratings: {region_b}\")\n",
    "# Output the test results\n",
    "print(f\"Mann-Whitney U statistic: {stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference in wine quality ratings between the two regions.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in wine quality ratings between the two regions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd928c09-30d9-405c-80ec-933f58c44980",
   "metadata": {},
   "source": [
    "Some details about the previous code:\n",
    "\n",
    "- The two samples of wine ratings are randomly generated within specified intervals: [80,95] for region A, and [85,100] for region B.\n",
    "- The test produces a double output: the U statistic and a p-value. In the Mann-Whitney U test, the U statistic is a measure of overlap between the two groups when all values are merged and ranked together. A larger value indicates more overlap and therefore less statistical difference. Meanwhile, the p-value is a probability that, when low (below 0.05), indicates a statistical difference between the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a4f634-c054-45c5-9094-95e679dd8acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e0d37bb-67ad-4eef-9b49-d1babf66aa93",
   "metadata": {},
   "source": [
    "# Wilcoxon Signed-Rank Test (for two paired samples/ one sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebc1a92-9abc-4b5b-a0a3-ec5a350e4ee2",
   "metadata": {},
   "source": [
    "The samples are related or matched in some way or represent two measurements of the same technique. More specifically, each sample is independent, but comes from the same population.\n",
    "\n",
    "- The Wilcoxon signed ranks test is a nonparametric statistical procedure for comparing two samples that are paired, or related.\n",
    "- The parametric equivalent to the Wilcoxon signed ranks test goes by names such as the Student’s t-test, t-test for matched pairs, t-test for paired samples, or t-test for dependent samples.\n",
    "\n",
    "The default assumption for the test, the null hypothesis, is that the two samples have the same distribution.\n",
    "\n",
    "- Fail to Reject H0: Sample distributions are equal.\n",
    "- Reject H0: Sample distributions are not equal.\n",
    "\n",
    "For the test to be effective, it requires at least 20 observations in each data sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6391046-e951-4d38-849c-cba167286df9",
   "metadata": {},
   "source": [
    "### two paired samples (e.g. before and after treatments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f587a9a-8675-4139-9747-1a056b9e9fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=1886.000, p=0.028\n",
      "Different distribution (reject H0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "# compare samples\n",
    "stat, p = wilcoxon(data1, data2)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distribution (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0199b956-74e6-47c4-8f22-d8c0bc6fe273",
   "metadata": {},
   "source": [
    "### one sample: testing the difference between the two samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "114685ae-ca1b-4143-b86b-af95adf8063b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=1886.000, p=0.028\n",
      "Different distribution (reject H0)\n"
     ]
    }
   ],
   "source": [
    "stat, p = wilcoxon(data1-data2)\n",
    "\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distribution (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d581d80-7c97-4d52-ac84-5e5bb306b307",
   "metadata": {},
   "source": [
    "Unlike the Mann-Whitney U test which compares two independent data groups to detect whether there is a statistical difference in their distributions or not, the Wilcoxon signed-rank test assumes both groups are related and the significant difference between their group medians is tested.\n",
    "\n",
    "This test could be applied for instance if we want to analyze significant differences for two sets of ratings for wine produced in the same region: one before applying an innovative preservation technique, and one after applying it.\n",
    "\n",
    "The application of Wilcoxon signed-rank test using Python is extremely similar to the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d1cc8b1-4efc-4c07-906d-d4f55049db24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings before: [91 88 92 89 91 94 87 91 92 89]\n",
      "Ratings after: [92 88 95 91 90 95 90 94 91 90]\n",
      "Wilcoxon statistic: 6.0\n",
      "P-value: 0.045797938810819776\n",
      "There is a significant difference in wine quality ratings after applying the preservation technique.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Synthetic data generation: wine quality ratings before and after using a preservation technique\n",
    "np.random.seed(42)\n",
    "before = np.random.randint(85, 95, size=10)\n",
    "after = before + np.random.randint(-2, 5, size=10)\n",
    "\n",
    "# Apply Wilcoxon Signed-Rank Test\n",
    "stat, p_value = wilcoxon(before, after)\n",
    "\n",
    "# Output the data\n",
    "print(f\"Ratings before: {before}\")\n",
    "print(f\"Ratings after: {after}\")\n",
    "#Output the test results\n",
    "print(f\"Wilcoxon statistic: {stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference in wine quality ratings after applying the preservation technique.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in wine quality ratings after applying the preservation technique.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86656b45-d3f5-40a6-99e4-3e31e7cbf228",
   "metadata": {},
   "source": [
    "The test statistic is calculated as the sum of the ranks of non-zero differences between paired samples, constituting an indicator of the magnitude and direction of changes between the two samples. Again, the Python implementation of this test applies these calculations internally for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66654e5-d0e0-49de-acd9-49aaf8360f1a",
   "metadata": {},
   "source": [
    "# Kruskal-Wallis H Test (ANOVA: for more than two independent samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b913c6b-37e7-40de-a807-8ff112753869",
   "metadata": {},
   "source": [
    "The Kruskal-Wallis test is a nonparametric version of the one-way analysis of variance test or ANOVA for short. It is named for the developers of the method, William Kruskal and Wilson Wallis. This test can be used to determine whether more than two independent samples have a different distribution. It can be thought of as the generalization of the Mann-Whitney U test.\n",
    "\n",
    "When the Kruskal-Wallis H-test leads to significant results, then at least one of the samples is different from the other samples. However, the test does not identify where the difference(s) occur. Moreover, it does not identify how many differences occur. To identify the particular differences between sample pairs, a researcher might use sample contrasts, or post hoc tests, to analyze the specific sample pairs for significant difference(s). The Mann-Whitney U-test is a useful method for performing sample contrasts between individual sample sets.\n",
    "\n",
    " - Fail to Reject H0: All sample distributions are equal.\n",
    " - Reject H0: One or more sample distributions are not equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ab6e5a3-7eb8-4b49-843e-62bd917e8bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data1 = np.random.randn(100)*5 + 50\n",
    "data2 = np.random.randn(100)*5 + 50\n",
    "data3 = np.random.randn(100)*5 + 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89174358-8dd5-4596-a9a9-c57649e77ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=1886.000, p=0.001\n",
      "Different distribution (reject H0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "stats,p=kruskal(data1,data2,data3)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "alpha=0.05\n",
    "\n",
    "if p>alpha:\n",
    "    print('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distribution (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4fb276-4c72-4918-9496-09642a8d0989",
   "metadata": {},
   "source": [
    "the Kruskal-Wallis test is the go-to option when there are more than two data groups we want to compare in terms of statistically significant differences between their distributions. The below example is applied similarly as the previous two, this time evaluating the existence or absence of significant differences between wine ratings for producers in three different regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e60023ea-ea18-44e7-a690-a52a92b6fdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region A ratings: [86 83 92 94 90 87 92 84 86 89 82 86 90 90 87]\n",
      "Region B ratings: [89 88 92 92 87 90 89 86 92 96 98 90 86 96 89]\n",
      "Region C ratings: [75 86 84 80 87 86 83 75 85 85 89 84 86 86 89]\n",
      "Kruskal-Wallis statistic: 16.63300149217167\n",
      "P-value: 0.0002444497611367245\n",
      "There is a significant difference in wine quality ratings among the regions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "# Synthetic data generation\n",
    "np.random.seed(42)\n",
    "region_a = np.random.randint(80, 95, size=15)\n",
    "region_b = np.random.randint(85, 100, size=15)\n",
    "region_c = np.random.randint(75, 90, size=15)\n",
    "\n",
    "# Apply Kruskal-Wallis test\n",
    "stat, p_value = kruskal(region_a, region_b, region_c)\n",
    "\n",
    "# Output the data\n",
    "print(f\"Region A ratings: {region_a}\")\n",
    "print(f\"Region B ratings: {region_b}\")\n",
    "print(f\"Region C ratings: {region_c}\")\n",
    "# Output the test results\n",
    "print(f\"Kruskal-Wallis statistic: {stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference in wine quality ratings among the regions.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in wine quality ratings among the regions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b67cbc-7c6f-4410-823c-b2d678319672",
   "metadata": {},
   "source": [
    "The returned Kruskal-Wallis statistic compares the ranks of data values across groups. Higher values of the statistic are a stronger indicator of having significantly different distributions between groups. Therefore, unlike the Mann-Whitney U test, a higher statistic for Kruskal-Wallis test yields a lower p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aeedb6-cf78-47ab-a170-9d53f9f360ae",
   "metadata": {},
   "source": [
    "# Friedman Test (repeated measures ANOVA: for more than two paired samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e712ef-e22f-4627-bccb-ae2922f924c7",
   "metadata": {},
   "source": [
    "The test assumes two or more paired data samples with 10 or more samples per group.\n",
    "\n",
    "The Friedman test is a nonparametric statistical procedure for comparing more than two samples that are related. The parametric equivalent to this test is the repeated measures analysis of variance (ANOVA). When the Friedman test leads to significant results, at least one of the samples is different from the other samples.\n",
    "\n",
    "The default assumption, or null hypothesis, is that the multiple paired samples have the same distribution. A rejection of the null hypothesis indicates that one or more of the paired samples has a different distribution.\n",
    "\n",
    "- Fail to Reject H0: Paired sample distributions are equal.\n",
    "- Reject H0: Paired sample distributions are not equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae076794-f438-48b1-8ebf-70bac9e7a168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=9.360, p=0.009\n",
      "Different distributions (reject H0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate three independent samples\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 50\n",
    "data3 = 5 * randn(100) + 52\n",
    "# compare samples\n",
    "stat, p = friedmanchisquare(data1, data2, data3)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde10e3-2d1a-4791-9c56-bf77a6a10b93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89f1aaa-77e8-4c61-adb2-92e4ee3c7353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f965af9-e09f-4d19-a54d-25337c079ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
